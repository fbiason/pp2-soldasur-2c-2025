# üåê Scraper de Productos PEISA

Este m√≥dulo realiza **scraping real** del sitio web de PEISA para obtener el cat√°logo de productos actualizado.

## üìç Ubicaci√≥n del Archivo Generado

El scraping guarda los productos en:
```
data/products_catalog.json
```

**NO** en `data/processed/` ni en `data/raw/`, sino directamente en la ra√≠z de `data/`.

## üöÄ Uso

### Opci√≥n 1: Scraping Real (Recomendado)

Extrae productos directamente de https://peisa.com.ar/productos:

```bash
python app/modules/scraping/product_scraper.py
```

### Opci√≥n 2: Cat√°logo de Respaldo

Si no tienes conexi√≥n o el sitio no est√° disponible:

```bash
python app/modules/scraping/product_scraper.py --no-scraping
```

## üìä Resultado del Scraping

El scraper extrae aproximadamente **50-70 productos** con la siguiente informaci√≥n:

```json
{
  "model": "Prima Tec Smart",
  "description": "Caldera doble servicio",
  "family": "Calderas",
  "type": "Producto de calefacci√≥n",
  "power_w": 0,
  "features": [],
  "applications": [],
  "liters": 0,
  "max_pressure_bar": 10,
  "dimensions": "N/A",
  "url": "https://peisa.com.ar/productos/prima-tec-smart"
}
```

### Familias de Productos Extra√≠das

- **Calderas**: Prima Tec Smart, Diva Tecno, Summa Condens, etc.
- **Radiadores**: Broen, Broen Plus, Tropical, Gamma, etc.
- **Termotanques**: El√©ctricos, solares, etc.
- **Climatizaci√≥n Piscinas**: Bombas de calor, TX70, TX40, etc.
- **Otros**: Termostatos, sistemas, accesorios, etc.

## üîÑ Flujo de Datos

```
PEISA Website (https://peisa.com.ar/productos)
    ‚Üì
product_scraper.py (scraping)
    ‚Üì
data/products_catalog.json
    ‚Üì
rag_engine_v2.py (RAG/Chatbot)
```

## üõ†Ô∏è Dependencias

El scraper requiere:

```
beautifulsoup4==4.13.3
requests==2.32.3
lxml==6.0.2
```

Ya est√°n incluidas en `requirements.txt`.

## üìù Estructura HTML de PEISA

El scraper est√° optimizado para la estructura actual de PEISA:

```html
<a href="/productos/[nombre]">
  <article>
    <div class="text-peisared-600">CATEGOR√çA</div>
    <h4>NOMBRE PRODUCTO</h4>
    <p>Descripci√≥n del producto</p>
  </article>
</a>
```

## ‚öôÔ∏è Configuraci√≥n

### L√≠mite de Productos

Por defecto extrae hasta 50 productos. Para cambiar:

```python
# En product_scraper.py, l√≠nea ~46
for idx, card in enumerate(product_cards[:50], 1):  # Cambiar 50
```

### Timeout de Conexi√≥n

```python
# En product_scraper.py, l√≠nea ~31
response = requests.get(products_url, headers=headers, timeout=10)  # Cambiar 10
```

## üîç Verificaci√≥n

Para verificar que el scraping funcion√≥ correctamente:

```bash
# Ver contenido del archivo
cat data/products_catalog.json

# Contar productos
python -c "import json; print(len(json.load(open('data/products_catalog.json'))))"
```

## üêõ Soluci√≥n de Problemas

### Error: "No se encontraron productos"

- Verificar conexi√≥n a internet
- El sitio de PEISA puede haber cambiado su estructura HTML
- Usar modo `--no-scraping` como respaldo

### Error: "Connection timeout"

- Aumentar el timeout en la l√≠nea 31
- Verificar firewall/proxy
- Usar modo `--no-scraping`

### Error: "ModuleNotFoundError: beautifulsoup4"

```bash
pip install beautifulsoup4 requests lxml
```

## üìå Notas Importantes

1. **Respeto al servidor**: El scraper incluye pausas de 0.1s entre productos para no sobrecargar el servidor de PEISA.

2. **Cat√°logo de respaldo**: Si el scraping falla, autom√°ticamente usa un cat√°logo curado de 14 productos.

3. **Actualizaci√≥n**: Ejecuta el scraper peri√≥dicamente para mantener el cat√°logo actualizado.

4. **Ubicaci√≥n correcta**: El archivo DEBE estar en `data/products_catalog.json` (no en subdirectorios) para que el RAG Engine lo encuentre.

## üîó Integraci√≥n con el Sistema

El cat√°logo generado es usado por:

- **RAG Engine V2** (`app/modules/chatbot/rag_engine_v2.py`)
- **Chatbot Soldy** (para recomendaciones de productos)
- **Sistema de b√∫squeda vectorial** (FAISS)

## üìö M√°s Informaci√≥n

- Documentaci√≥n del chatbot: `docs/CHATBOT_SOLDY.md`
- Estructura del proyecto: `docs/README_MODULOS.md`
- Gu√≠a r√°pida: `docs/QUICKSTART.md`
